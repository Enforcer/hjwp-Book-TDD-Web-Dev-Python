[[ai_preface]]
[preface]
== Preface to the Third Edition: TDD in the age of AI

Is there any point in learning TDD now that AI can write code for you?
A single prompt could probably generate the entire example application in this book,
including all its tests, and the infrastructure config for automated deployment too.

The truth is that it's too early to tell.  AI is still in its infancy,
and who knows what it'll be able to do in a few years or even months' time.


=== AI is both insanely impressive and incredibly unreliable

What we do know is that right now,
AI is both insanely impressive and incredibly unreliable.

Beyond being able to understand and respond to prompts in normal human language--
it's easy to forget how absolutely extraordinary that is; literally science-fiction
a few years ago--AI tools can generate working code, they can generate tests,
they can help us to break down requirements, brainstorm solutions,
quickly prototype new technologies.  It's genuinely astonishing.

As we're all finding out though, this all comes with a massive "but".
AI outputs are frequently plagued by hallucinations,
and in the world of code, that means things that just won't work,
even if they look plausible.
Worse than that, they can produce code that appears to work,
but is full of subtle bugs, security issues, or performance nightmares.
From a code quality point of view, we know that AI tools will often produce
code that's filled with copy-paste and duplication, weird hacks,
and undecipherable spaghetti code that spells a maintenance nightmare.


=== Mitigations for AI's Shortcomings Sure Look A Lot Like TDD

If you read the advice, even from AI companies themselves,
about the best way to work with AI, you'll find date that it
performs best when working in small, well-defined contexts,
with frequent checks for correctness.
When taking on larger tasks, the advice is to break them down into smaller,
well-defined pieces, with clearly defined success criteria.

When we're thinking about the problem of hallucinations,
it sure seems like having a comprehensive test suite and running it frequently,
is going to be a must-have.

When we're thinking about code quality, the idea of having a human in the loop,
with frequent pauses for review and refactoring,
again seems like a key mitigation.

In short, all of the techniques of Test-Driven Development that are outlined in this book:

* Defining a test that describes each small change of functionality,
  before we write the code for it

* Breaking our problem down into small pieces and working incrementally,
  with frequent test runs to catch bugs, regressions, and hallucinations

* The "refactor" step in Red/Green/Refactor, which gives us a regular
  reminder for the human in the loop to review and improve the code.


TDD is all about finding a structured, safer way of developing software,
reducing the risk of bugs and regressions and improving code quality,
and these are very much the exact same things that we need to achieve
when working with AI.


=== Leaky Abstractions and the Importance of Experience

https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/["Leaky abstractions"] are a diagnosis of a common problem in software development,
whereby higher-level abstractions fail in subtle ways,
and the complexities of the underlying system leak through.

It's for this reason that, when the switch to third-generation languages (3GLs) happened,
programmers who understood the underlying machine code were often the most effective
at using the new languages like C and Fortran.

In a similar way, AI offers us a new, higher-level abstraction around writing code,
but we can already see the "leaks" in the form of hallucinations and poor code quality.
And by analogy to the 3GLs, the programmers who are going to be most effective with AI
are going to be the ones who "know what good looks like",
both in terms of code quality, test structure,
but also what a safe and reliable workflow for software development looks like.

moar points:

* something about my own experience with ai tools:
  good at writing somewhat ugly tests
  tends to produce code that's a total mess
  gets stuck in a loop when trying more complex tasks

* learn by doing it manually so you know when doing it automatically is going wrong

* discerning partner rather than passive recipient

* you still need to stand by the code you get your ai to write. if it's broken, that's your fault.

* something about actually understanding the code that's produced.



////

first cut follows 

AI tools regularly hallucinate things that don't exist,
and when left to their own devices,
they produce code which, even when it does work,
tends towards horrendous duplication,
strange hacks, and is soon completely unmaintainable.

What we're finding is that AI works best when it works on small,
well-defined problems, with frequent checks for correctness
to catch those hallucinations, and regular review
to ensure that the code that comes out is maintainable.

In short, all of the techniques of TDD:

* We start with a failing test that defines a small new piece of functionality
  that we'd like to add to our code

* We train ourselves to work incrementally, in small steps,
  slicing our problem up into small chunks, and working on them one at a time.

* We regularly run our entire test suite to catch any bugs or regressions
  or hallucinations as soon as they happen.

* And we we are regularly prompted to review and refactor our code,
  to make sure it is expressive and maintainable.

////


=== The AI-Enabled Workflow of the Future


The AI-enabled workflow of the future
will look very different to what we have now,
but all the indications are that the most effective approach is going to be
incremental, have checks and balances to avoid hallucinations,
and systematically involve humans in the loop to ensure quality.

And the closest workflow we have to that today, is TDD.

