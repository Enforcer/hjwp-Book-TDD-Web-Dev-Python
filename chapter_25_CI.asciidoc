[[chapter_25_CI]]
== CI: Continuous Integration


.Warning, Chapter Update in Progress
*******************************************************************************
ðŸš§ Warning, this chapter is very much a rough sketch at the moment. ðŸš§

Work in progress: switch away from Jenkins,
to something more modern.
I'm still going to avoid the obvious choice of GitHub Actions,
I'm hoping to pick something that's at least open source (eg GitLab),
if not fully self-hosted / free software (like Woodpecker CI).

Also planning to add the CD part, ie automated deployments. 
watch this spaceeee

*******************************************************************************


((("Continuous Integration (CI)", id="CI24")))
((("Continuous Integration (CI)", "benefits of")))
As our site grows, it takes longer and longer to run all of our functional tests.
If this continues, the danger is that we're going to stop bothering.

Rather than let that happen, we can automate the running of functional tests
by setting up "Continuous Integration", or CI.
That way, in day-to-day development,
we can just run the FT that we're working on at that time,
and rely on CI to run all the other tests automatically
and let us know if we've broken anything accidentally.

The unit tests should stay fast enough that we can keep running
the full suite locally, every few seconds.

NOTE: Continuous Integration is another practice that was popularised by
    Kent Beck's 
    https://martinfowler.com/bliki/ExtremeProgramming.html[Extreme Programming (XP)]
    movement in the 1990s.

=== Choosing a CI service

((("Continuous Integration (CI)", "choosing a service")))
TODO chat re gha, hosted ci solutions, picked a relatable one.


=== Setting up GitLab

* start new ci/cd project, add repo url
* go to build -> pipelines
* use template python project

NOTE: GitLab free tier won't let you "mirror" a repo from elsewhere.
    You either need


change a of things., `/venv` -> `.venv`

ended up with this as first cut:


[role="sourcecode"]
..gitlab-ci.yml
====
[source,yaml]
----
# Official language image. Look for the different tagged releases at:
# https://hub.docker.com/r/library/python/tags/
image: python:latest

# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"

# https://pip.pypa.io/en/stable/topics/caching/
cache:
  paths:
    - .cache/pip

before_script:
  - python --version ; pip --version  # For debugging
  - pip install virtualenv
  - virtualenv .venv
  - source .venv/bin/activate

test:
  script:
    - pip install -r requirements.txt
    - pip install selenium
    # unit tests
    - python src/manage.py test lists accounts
    # (if those pass) all tests, incl. functional. yes we need that cd.
    - cd src && python manage.py test

----
====


=== First Build!

fails as follows:


* TODO: consider deliberately forgetting to pip install selenium

----
[...]
Ran 63 tests in 8.658s
FAILED (errors=8)

selenium.common.exceptions.WebDriverException: Message: Process unexpectedly closed with status 255
----

unit tests pass but fts are failing

firefox isn't installed.

[role="sourcecode"]
..gitlab-ci.yml
====
[source,yaml]
  before_script:
    # install firefox
    - apt update -y && apt install -y firefox-esr
    - python --version ; pip --version  # For debugging
    - pip install virtualenv
    - virtualenv .venv
    - source .venv/bin/activate
----
====

and...


[role="skipme small-code"]
----
$ apt-get update -y && apt-get install -y firefox-esr
Get:1 http://deb.debian.org/debian bookworm InRelease [151 kB]
Get:2 http://deb.debian.org/debian bookworm-updates InRelease [55.4 kB]
Get:3 http://deb.debian.org/debian-security bookworm-security InRelease [48.0 kB]
Get:4 http://deb.debian.org/debian bookworm/main amd64 Packages [8792 kB]
Get:5 http://deb.debian.org/debian bookworm-updates/main amd64 Packages [13.5 kB]
Get:6 http://deb.debian.org/debian-security bookworm-security/main amd64 Packages [245 kB]
Fetched 9305 kB in 1s (9127 kB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
[...]
The following NEW packages will be installed:
  adwaita-icon-theme alsa-topology-conf alsa-ucm-conf at-spi2-common
  at-spi2-core dbus dbus-bin dbus-daemon dbus-session-bus-common
  dbus-system-bus-common dbus-user-session dconf-gsettings-backend
  dconf-service dmsetup firefox-esr fontconfig fontconfig-config
[...]
Get:117 http://deb.debian.org/debian-security bookworm-security/main amd64
firefox-esr amd64 128.7.0esr-1~deb12u1 [69.8 MB]
[...]
Selecting previously unselected package firefox-esr.
Preparing to unpack .../105-firefox-esr_128.7.0esr-1~deb12u1_amd64.deb ...
Adding 'diversion of /usr/bin/firefox to /usr/bin/firefox.real by firefox-esr'
Unpacking firefox-esr (128.7.0esr-1~deb12u1) ...
[...]
Setting up firefox-esr (128.7.0esr-1~deb12u1) ...
update-alternatives: using /usr/bin/firefox-esr to provide
/usr/bin/x-www-browser (x-www-browser) in auto mode
[...]

ERROR: test_multiple_users_can_start_lists_at_different_urls
(functional_tests.test_simple_list_creation.NewVisitorTest.test_multiple_users_can_start_lists_at_different_urls)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File "/builds/hjwp/book-example/src/functional_tests/base.py", line 30, in setUp
    self.browser = webdriver.Firefox()
                   ~~~~~~~~~~~~~~~~~^^
[...]
selenium.common.exceptions.WebDriverException: Message: Process unexpectedly
closed with status 1
 ---------------------------------------------------------------------
Ran 63 tests in 3.654s
FAILED (errors=8)
----

Ooops still not.



[role="sourcecode"]
..gitlab-ci.yml
====
[source,yaml]
----
variables:
  # Change pip's cache directory to be inside the project directory since we can
  # only cache local items.
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  # make firefox run without a display
  MOZ_HEADLESS: "1"
----
====



* TODO: need to show a flaky test failure here



=== Taking Screenshots

((("Continuous Integration (CI)", "screenshots", id="CIscreen24")))
((("screenshots", id="screen24")))
((("debugging", "screenshots for", id="DBscreen24")))
To be able to debug unexpected failures that happen on a remote server,
it would be good to see a picture of the screen at the moment of the failure,
and maybe also a dump of the HTML of the page.

We can do that using some custom logic in our FT class `tearDown`.
We'll need to do a bit of introspection of `unittest` internals,
a private attribute called `._outcome`,
but this will work:

[role="sourcecode"]
.src/functional_tests/base.py (ch23l006)
====
[source,python]
----
import os
import time
from datetime import datetime
from pathlib import Path
[...]
MAX_WAIT = 5

SCREEN_DUMP_LOCATION = Path(__file__).absolute().parent / "screendumps"
[...]

    def tearDown(self):
        if self._test_has_failed():
            if not SCREEN_DUMP_LOCATION.exists():
                SCREEN_DUMP_LOCATION.mkdir(parents=True)
            self.take_screenshot()
            self.dump_html()
        self.browser.quit()
        super().tearDown()

    def _test_has_failed(self):
        # slightly obscure but couldn't find a better way!
        return self._outcome.result.failures or self._outcome.result.errors
----
====


We first create a directory for our screenshots if necessary.
Then we iterate through all the open browser tabs and pages,
and use a Selenium methods, `get_screenshot_as_file()`
and the attribute `browser.page_source`,
for our image and HTML dumps, respectively:

[role="sourcecode"]
.src/functional_tests/base.py (ch23l007)
====
[source,python]
----
    def take_screenshot(self):
        path = SCREEN_DUMP_LOCATION / self._get_filename("png")
        print("screenshotting to", path)
        self.browser.get_screenshot_as_file(str(path))

    def dump_html(self):
        path = SCREEN_DUMP_LOCATION / self._get_filename("html")
        print("dumping page HTML to", path)
        path.write_text(self.browser.page_source)
----
====


And finally here's a way of generating a unique filename identifier,
which includes the name of the test and its class, as well as a timestamp:

[role="sourcecode small-code"]
.src/functional_tests/base.py (ch23l008)
====
[source,python]
----
    def _get_filename(self, extension):
        timestamp = datetime.now().isoformat().replace(":", ".")[:19]
        return (
            f"{self.__class__.__name__}.{self._testMethodName}-{timestamp}.{extension}"
        )
----
====

You can test this first locally by deliberately breaking one of the tests,
with a `self.fail()` for example, and you'll see something like this:

[role="dofirst-ch21l009"]
----
[...]
.Fscreenshotting to ...goat-book/src/functional_tests/screendumps/MyListsTest.t
est_logged_in_users_lists_are_saved_as_my_lists-[...]
dumping page HTML to ...goat-book/src/functional_tests/screendumps/MyListsTest.
test_logged_in_users_lists_are_saved_as_my_lists-[...]
----

Revert the `self.fail()`, then commit and push:

[role="dofirst-ch21l010"]
[subs="specialcharacters,quotes"]
----
$ *git diff*  # changes in base.py
$ *echo "src/functional_tests/screendumps" >> .gitignore*
$ *git commit -am "add screenshot on failure to FT runner"*
$ *git push*
----

* TODO resume here

And when we rerun the build on Gitlab, we see something like this:

[role="skipme small-code"]
----
screenshotting to ./builds/hjwp/book-example/functional_tests/
screendumps/LoginTest.test_can_get_email_link_to_log_in-window0-2014-01-22T17.45.12.png
dumping page HTML to ./builds/hjwp/book-example/functional_tests/
screendumps/LoginTest.test_can_get_email_link_to_log_in-window0-2014-01-22T17.45.12.html
----


* TODO show these in gitlab ui


And then we look at the screenshot, as shown in <<normal-screenshot>>.

// TODO needs updating for latest bootstrap etc

[[normal-screenshot]]
[role="width-75"]
.Screenshot looking normal
image::images/twp2_2411.png["Screenshot of site page"]



=== If in Doubt, Try Bumping the Timeout!

((("", startref="CIscreen24")))
((("", startref="screen24")))
((("", startref="DBscreen24")))
((("Continuous Integration (CI)", "timeout bumping")))
((("CI", "timeout bumping")))
Hm.  No obvious clues there.
Well, when in doubt, bump the timeout, as the old adage goes:

[role="sourcecode skipme"]
.src/functional_tests/base.py
====
[source,python]
----
MAX_WAIT = 10
----
====

Then we can rerun the build by pushing, and confirm it now works,


* TODO screenshot



=== Alternatives: Woodpecker and Forgejo

you need your own server for these.
i managed to get forgejo up and running in about 40 minutes.

be careful with security!
these things tend to assume you're on a private network,
or that your code is entirely public.

eg: in forgejo to avoid letting the whole internet sign up and rootle around in your ci (not that anyone would care, really, but, you know)

[role="skipme"]
----
DISABLE_REGISTRATION: true
----



=== Running Our JavaScript Tests in CI

((("Continuous Integration (CI)", "QUnit JavaScript tests", id="CIjs5")))
((("JavaScript testing", "in CI", secondary-sortas="CI", id="JSCI")))
There's a set of tests we almost forgot--the JavaScript tests.
Currently our "test runner" is an actual web browser.q
To get them running in CI, we need a command-line test runner.

* TODO: npm-browser-runner


==== Installing node

It's time to stop pretending we're not in the JavaScript game.
We're doing web development.  That means we do JavaScript.
That means we're going to end up with node.js on our computers.
It's just the way it has to be.

Follow the instructions on the http://nodejs.org/[node.js homepage].
There are installers for Windows and Mac,
and repositories for popular Linux distros.

* TODO: mention nvm


==== Adding A Build Steps for Js

* TODO 


((("", startref="CIjs5")))
((("", startref="JSCI")))

=== Tests now pass

And there we are!  A complete CI build featuring all of our tests!



* TODO screenshot

Nice to know that, no matter how lazy I get
about running the full test suite on my own machine, the CI server will catch me.
Another one of the Testing Goat's agents in cyberspace, watching over us...


But, to really finish this off, you should really take a look at <<appendix_CD>>.

I've moved it to an appendix tho, cos it's so gitlab-heavy.

onto our last chapter!



.Tips on CI and Selenium Best Practices
*******************************************************************************

Set up CI as soon as possible for your project::
    As soon as your functional tests take more than a few seconds to run,
    you'll find yourself avoiding running them all. Give this job to a CI
    server, to make sure that all your tests are getting run somewhere.
    ((("Selenium", "best CI practices")))
    ((("Continuous Integration (CI)", "tips")))
    

Set up screenshots and HTML dumps for failures::
    Debugging test failures is easier if you can see what the page looked
    like when the failure occurred.  This is particularly useful for debugging
    CI failures, but it's also very useful for tests that you run locally.
    ((("screenshots")))
    ((("debugging", "screenshots for")))
    ((("HTML", "screenshot dumps")))

Be prepared to bump your timeouts::
    A CI server may not be as speedy as your laptop,
    especially if it's under load, running multiple tests at the same time.
    Be prepared to be even more generous with your timeouts,
    in order to minimise the chance of random failures.
    ((("Flaky tests")))

Take the next step, CD (Continuous Delivery)::
    Once we're running tests automatically,
    we can take the next step which is to automated our deployments
    (when the tests pass). See <<appendix_CD>> for a worked example.
    ((("Continuous Delivery (CD)")))
    
*******************************************************************************

